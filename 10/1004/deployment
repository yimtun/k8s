清理环境

kubectl  delete svc kubia
kubectl  delete  rc kubia-v2
kubectl  get rs,rc
No resources found.



创建 deployment


cat > dp.yaml << EOF
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: kubia
spec:
  replicas: 3
  template:
    metadata:
      name: kubia
      labels:
        app: kubia
    spec:
      containers:
      - image: luksa/kubia:v1
        imagePullPolicy: IfNotPresent
        name: nodejs
EOF



kubectl  get pod -L app=kubia
No resources found.


kubectl  create  -f dp.yaml  --record

加上  --record  rollout 才有信息


kubectl  get pod -L app=kubia
NAME                     READY   STATUS    RESTARTS   AGE   APP=KUBIA
kubia-5bd5dd8bf9-ghzq4   1/1     Running   0          33s   
kubia-5bd5dd8bf9-tfnds   1/1     Running   0          33s   
kubia-5bd5dd8bf9-zfdn6   1/1     Running   0          33s   


kubectl  get rs -L app=kubia  --show-labels 
NAME               DESIRED   CURRENT   READY   AGE    APP=KUBIA   LABELS
kubia-5bd5dd8bf9   3         3         3       103s               app=kubia,pod-template-hash=5bd5dd8bf9



rs 直接管理pod




kubectl  rollout status deployment kubia
deployment "kubia" successfully rolled out


为dp 创建一个 svc


kubectl  expose  deployment kubia  --port 80
service/kubia exposed


kubectl  api-resources  | grep  deployments
deployments                       deploy       apps                           true         Deployment
deployments                       deploy       extensions                     true         Deployment





kubectl  get svc kubia -o wide
NAME    TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE    SELECTOR
kubia   ClusterIP   10.254.114.72   <none>        80/TCP    2m3s   app=kubia


node02

[root@node02 ~]# while true;do curl 10.254.114.72;done;
curl: (7) Failed connect to 10.254.114.72:80; Connection refused
curl: (7) Failed connect to 10.254.114.72:80; Connection refused
curl: (7) Failed connect to 10.254.114.72:80; Connection refused
curl: (7) Failed connect to 10.254.114.72:80; Connection refused
curl: (7) Failed connect to 10.254.114.72:80; Connection refused
curl: (7) Failed connect to 10.254.114.72:80; Connection refused
curl: (7) Failed connect to 10.254.114.72:80; Connection refused
curl: (7) Failed connect to 10.254.114.72:80; Connection refused



服务没有启动



修改  yaml

cat > dp.yaml  << EOF
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: kubia
spec:
  replicas: 3
  template:
    metadata:
      name: kubia
      labels:
        app: kubia
    spec:
      containers:
      - image: luksa/kubia:v1
        imagePullPolicy: IfNotPresent
        name: nodejs
---
apiVersion: v1
kind: Service
metadata:
  name: kubia
spec:
  type: NodePort
  selector:
    app: kubia
  ports:
  - port: 80
    targetPort: 8080
EOF



重新创建  dploy  和  svc



kubectl  delete -f dp.yaml 
deployment.apps "kubia" deleted
service "kubia" deleted







kubectl  create  -f dp.yaml  --record 
deployment.apps/kubia created
service/kubia created





kubectl  get  pod -l app=kubia -owide --show-labels 
NAME                     READY   STATUS    RESTARTS   AGE    IP            NODE             NOMINATED NODE   LABELS
kubia-5bd5dd8bf9-7bzc8   1/1     Running   0          2m1s   172.30.6.10   192.168.10.242   <none>           app=kubia,pod-template-hash=5bd5dd8bf9
kubia-5bd5dd8bf9-bv55d   1/1     Running   0          2m     172.30.6.12   192.168.10.242   <none>           app=kubia,pod-template-hash=5bd5dd8bf9
kubia-5bd5dd8bf9-t29c9   1/1     Running   0          2m1s   172.30.6.11   192.168.10.242   <none>           app=kubia,pod-template-hash=5bd5dd8bf9



kubectl  get  svc   kubia  -owide
NAME    TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE     SELECTOR
kubia   NodePort   10.254.195.14   <none>        80:56705/TCP   2m38s   app=kubia



kubectl  get  svc   kubia  -oyaml
apiVersion: v1
kind: Service
metadata:
  annotations:
    kubernetes.io/change-cause: kubectl create --filename=dp.yaml --record=true
  creationTimestamp: 2019-06-16T04:15:46Z
  name: kubia
  namespace: default
  resourceVersion: "6186345"
  selfLink: /api/v1/namespaces/default/services/kubia
  uid: 6a969977-8fed-11e9-8483-5254003d139c
spec:
  clusterIP: 10.254.195.14
  externalTrafficPolicy: Cluster
  ports:
  - nodePort: 56705
    port: 80
    protocol: TCP
    targetPort: 8080
  selector:
    app: kubia
  sessionAffinity: None
  type: NodePort
status:
  loadBalancer: {}






[root@node02 ~]# while true;do curl 10.254.195.14;done;

[root@node02 ~]# while true;do curl 10.254.195.14;done;
This is v1 running in pod kubia-5bd5dd8bf9-bv55d
This is v1 running in pod kubia-5bd5dd8bf9-7bzc8
This is v1 running in pod kubia-5bd5dd8bf9-t29c9
This is v1 running in pod kubia-5bd5dd8bf9-bv55d
This is v1 running in pod kubia-5bd5dd8bf9-7bzc8
This is v1 running in pod kubia-5bd5dd8bf9-t29c9
This is v1 running in pod kubia-5bd5dd8bf9-bv55d
This is v1 running in pod kubia-5bd5dd8bf9-7bzc8
This is v1 running in pod kubia-5bd5dd8bf9-t29c9
This is v1 running in pod kubia-5bd5dd8bf9-bv55d
This is v1 running in pod kubia-5bd5dd8bf9-7bzc8





发布更新

kubectl  get deployments. kubia  -o yaml
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: "1"
    kubernetes.io/change-cause: kubectl create --filename=dp.yaml --record=true
  creationTimestamp: 2019-06-16T04:15:46Z
  generation: 1
  labels:
    app: kubia
  name: kubia
  namespace: default
  resourceVersion: "6186390"
  selfLink: /apis/extensions/v1beta1/namespaces/default/deployments/kubia
  uid: 6a932e40-8fed-11e9-8483-5254003d139c
spec:
  progressDeadlineSeconds: 600
  replicas: 3
  revisionHistoryLimit: 2
  selector:
    matchLabels:
      app: kubia
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:





升级策略 类型 RollingUpdate
 strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate


spec:
  progressDeadlineSeconds: 600
  revisionHistoryLimit: 2






控制升级速度

kubectl  patch  deployments. kubia  -p '{"spec":{"minReadySeconds":10}}'

kubectl  get deployments. kubia  -o yaml | grep Ready
  minReadySeconds: 10


触发滚动升级

while true;do curl 10.254.195.14;done;


kubectl  set image deployment kubia nodejs=luksa/kubia:v2 --record







kubectl  get pod -l app=kubia
NAME                     READY   STATUS        RESTARTS   AGE
kubia-5bd5dd8bf9-t29c9   1/1     Terminating   0          77m
kubia-7d9f9cc8d-8jqnl    1/1     Running       0          34s
kubia-7d9f9cc8d-bcxhj    1/1     Running       0          46s
kubia-7d9f9cc8d-rb29t    1/1     Running       0          57s



kubectl  get pod -l app=kubia
NAME                    READY   STATUS    RESTARTS   AGE
kubia-7d9f9cc8d-8jqnl   1/1     Running   0          64s
kubia-7d9f9cc8d-bcxhj   1/1     Running   0          76s
kubia-7d9f9cc8d-rb29t   1/1     Running   0          87s





kubectl  get rs
NAME               DESIRED   CURRENT   READY   AGE
kubia-5bd5dd8bf9   0         0         0       78m
kubia-7d9f9cc8d    3         3         3       2m12s




kubectl  get deployments. kubia   -o yaml |grep image
    kubernetes.io/change-cause: kubectl set image deployment kubia nodejs=luksa/kubia:v2
      - image: luksa/kubia:v2
        imagePullPolicy: IfNotPresent



[root@master01 ~]# kubectl  get rs 
NAME               DESIRED   CURRENT   READY   AGE
kubia-5bd5dd8bf9   0         0         0       80m
kubia-7d9f9cc8d    3         3         3       4m4s


0 是上一个版本的 rs  回滚的时候会需要之前的 rs





回滚 deploy

升级到  v3

kubectl  set image deployment kubia nodejs=luksa/kubia:v3 --record


[root@node02 ~]# while true;do curl 10.254.195.14;done;
Some internal error has occurred! This is pod kubia-f74d74ff7-46vl4
This is v2 running in pod kubia-7d9f9cc8d-8jqnl
This is v2 running in pod kubia-7d9f9cc8d-bcxhj
This is v2 running in pod kubia-7d9f9cc8d-rb29t
Some internal error has occurred! This is pod kubia-f74d74ff7-46vl4
This is v2 running in pod kubia-7d9f9cc8d-8jqnl
This is v2 running in pod kubia-7d9f9cc8d-bcxhj
This is v2 running in pod kubia-7d9f9cc8d-rb29t
Some internal error has occurred! This is pod kubia-f74d74ff7-46vl4
Some internal error has occurred! This is pod kubia-f74d74ff7-ddbsl
Some internal error has occurred! This is pod kubia-f74d74ff7-f8lqw
Some internal error has occurred! This is pod kubia-f74d74ff7-46vl4
Some internal error has occurred! This is pod kubia-f74d74ff7-ddbsl
Some internal error has occurred! This is pod kubia-f74d74ff7-f8lqw
Some internal error has occurred! This is pod kubia-f74d74ff7-46vl4
Some internal error has occurred! This is pod kubia-f74d74ff7-ddbsl
Some internal error has occurred! This is pod kubia-f74d74ff7-f8lqw
Some internal error has occurred! This is pod kubia-f74d74ff7-46vl4
Some internal error has occurred! This is pod kubia-f74d74ff7-ddbsl
Some internal error has occurred! This is pod kubia-f74d74ff7-f8lqw
Some internal error has occurred! This is pod kubia-f74d74ff7-46vl4
Some internal error has occurred! This is pod kubia-f74d74ff7-ddbsl
Some internal error has occurred! This is pod kubia-f74d74ff7-f8lqw







kubectl  get rs
NAME               DESIRED   CURRENT   READY   AGE
kubia-5bd5dd8bf9   0         0         0       87m
kubia-7d9f9cc8d    0         0         0       10m
kubia-f74d74ff7    3         3         3       2m7s




升级出现问题  需要回退到上一个版本




kubectl  rollout  history  deployment  kubia
deployment.extensions/kubia 
REVISION  CHANGE-CAUSE
1         kubectl create --filename=dp.yaml --record=true
2         kubectl set image deployment kubia nodejs=luksa/kubia:v2 --record=true
3         kubectl set image deployment kubia nodejs=luksa/kubia:v3 --record=true



如果不指定 --record的话，CHANGE-CAUSE 字段将为空 none

快速回滚 到 前一个版本


kubectl  rollout undo deployment kubia

while true;do curl 10.254.195.14;done;
This is v2 running in pod kubia-7d9f9cc8d-2g857
Some internal error has occurred! This is pod kubia-f74d74ff7-46vl4
This is v2 running in pod kubia-7d9f9cc8d-rvpch
This is v2 running in pod kubia-7d9f9cc8d-4zh9b
This is v2 running in pod kubia-7d9f9cc8d-2g857
Some internal error has occurred! This is pod kubia-f74d74ff7-46vl4
This is v2 running in pod kubia-7d9f9cc8d-rvpch
This is v2 running in pod kubia-7d9f9cc8d-4zh9b

This is v2 running in pod kubia-7d9f9cc8d-4zh9b
This is v2 running in pod kubia-7d9f9cc8d-2g857
This is v2 running in pod kubia-7d9f9cc8d-rvpch
This is v2 running in pod kubia-7d9f9cc8d-4zh9b
This is v2 running in pod kubia-7d9f9cc8d-2g857
This is v2 running in pod kubia-7d9f9cc8d-rvpch
This is v2 running in pod kubia-7d9f9cc8d-4zh9b
This is v2 running in pod kubia-7d9f9cc8d-2g857
This is v2 running in pod kubia-7d9f9cc8d-rvpch
This is v2 running in pod kubia-7d9f9cc8d-4zh9b
This is v2 running in pod kubia-7d9f9cc8d-2g857




回滚成功 到 v2

kubectl  rollout  history  deployment  kubia
deployment.extensions/kubia 
REVISION  CHANGE-CAUSE
1         kubectl create --filename=dp.yaml --record=true
3         kubectl set image deployment kubia nodejs=luksa/kubia:v3 --record=true
4         kubectl set image deployment kubia nodejs=luksa/kubia:v2 --record=true





kubectl  get rs
NAME               DESIRED   CURRENT   READY   AGE
kubia-5bd5dd8bf9   0         0         0       92m
kubia-7d9f9cc8d    3         3         3       15m
kubia-f74d74ff7    0         0         0       6m56s


kubectl  get deployments. kubia   -o yaml |grep revisionHistoryLimit
  revisionHistoryLimit: 2


决定显示的 条数







回滚 Deployment 到特定的版本

kubectl  rollout  history  deployment  kubia
deployment.extensions/kubia 
REVISION  CHANGE-CAUSE
1         kubectl create --filename=dp.yaml --record=true
3         kubectl set image deployment kubia nodejs=luksa/kubia:v3 --record=true
4         kubectl set image deployment kubia nodejs=luksa/kubia:v2 --record=true



kubectl  rollout undo deployment kubia --to-revision=1

kubectl  get rs -l app=kubia
NAME               DESIRED   CURRENT   READY   AGE
kubia-5bd5dd8bf9   1         1         1       95m
kubia-7d9f9cc8d    3         3         3       19m
kubia-f74d74ff7    0         0         0       10m


[root@node02 ~]# while true;do curl 10.254.195.14;done;
This is v2 running in pod kubia-7d9f9cc8d-2g857
This is v1 running in pod kubia-5bd5dd8bf9-9ppz4
This is v1 running in pod kubia-5bd5dd8bf9-h9jsm
This is v2 running in pod kubia-7d9f9cc8d-4zh9b
This is v2 running in pod kubia-7d9f9cc8d-2g857
This is v1 running in pod kubia-5bd5dd8bf9-9ppz4
This is v1 running in pod kubia-5bd5dd8bf9-h9jsm
This is v2 running in pod kubia-7d9f9cc8d-4zh9b
This is v2 running in pod kubia-7d9f9cc8d-2g857
This is v1 running in pod kubia-5bd5dd8bf9-9ppz4





kubectl  get rs -l app=kubia
NAME               DESIRED   CURRENT   READY   AGE
kubia-5bd5dd8bf9   3         3         3       96m
kubia-7d9f9cc8d    0         0         0       19m
kubia-f74d74ff7    0         0         0       11m










rs 都是 deploy 维护 不要手动删除rs     删除deploy就会删除rs








[root@master01 ~]# kubectl  get deployments. kubia   -o yaml |grep revisionHistoryLimit
  revisionHistoryLimit: 2

[root@master01 ~]# kubectl  patch  deployments. kubia  -p '{"spec":{"revisionHistoryLimit":10}}'
deployment.extensions/kubia patched

[root@master01 ~]# kubectl  get deployments. kubia   -o yaml |grep revisionHistoryLimit
  revisionHistoryLimit: 10




回滚  经常升级  改造 线上的操作 每次操作 都会有风险 需要写操作的方案 大家评审 方案是否可行

方案里既包括执行动作 也要包含回滚动作  如果这一步执行不下去了 执行失败了 需要回滚 应该怎么去回滚
回滚方案是什么  是不是可行的   一定验证回滚方案  


没有回滚回来  相关组件的回滚 不能遗漏

有些操作是不可回滚的 

混滚时处于中间状态 很致命



和公司部署系统打通 没有严格依赖  k8s 部署  分组 强制分组 ？？？？




初次部署没法回滚


conredns   没有用   容器配置  内存 CPU 查看容器监控   决定扩缩容


业务区镜像市场 制作镜像

redis mysql  在k8s 上一层 解决 主备之类的关系


容器主机名 ip  改了    录入到 cmdb 里去了  

Deployment 滚动升级频率控制










































































































